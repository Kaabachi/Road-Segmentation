{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road-Segmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import RoadsDatasetTrain, RoadsDatasetTest\n",
    "from models.unet import UNet\n",
    "from models.resnet import ResNet\n",
    "from train import train\n",
    "from predict import predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural net parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "CRITERION = nn.BCELoss()\n",
    "\n",
    "# Image processing parameters\n",
    "PATCH_SIZE = 16\n",
    "LARGE_PATCH_SIZE = 96\n",
    "\n",
    "TRAIN_IMAGE_INITIAL_SIZE = 400\n",
    "NUMBER_PATCH_PER_TRAIN_IMAGE = (TRAIN_IMAGE_INITIAL_SIZE // PATCH_SIZE) * (TRAIN_IMAGE_INITIAL_SIZE // PATCH_SIZE)\n",
    "\n",
    "TEST_IMAGE_INITIAL_SIZE = 608\n",
    "NUMBER_PATCH_PER_TEST_IMAGE = (TEST_IMAGE_INITIAL_SIZE // PATCH_SIZE) * (TEST_IMAGE_INITIAL_SIZE // PATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading train data\n",
    "train_data_dir = \"./Datasets/training\"\n",
    "train_dataset = RoadsDatasetTrain(patch_size=PATCH_SIZE, large_patch_size=LARGE_PATCH_SIZE, number_patch_per_image=NUMBER_PATCH_PER_TRAIN_IMAGE,image_initial_size= TRAIN_IMAGE_INITIAL_SIZE, root_dir=train_data_dir)\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Loading test data\n",
    "test_data_dir = \"./Datasets/test_set_images\"\n",
    "test_dataset = RoadsDatasetTest(patch_size=PATCH_SIZE, large_patch_size=LARGE_PATCH_SIZE, number_patch_per_image=NUMBER_PATCH_PER_TEST_IMAGE,image_initial_size= TEST_IMAGE_INITIAL_SIZE,root_dir=test_data_dir)\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unet = UNet()\n",
    "train(model=unet, dataloader=train_dataloader, epochs=EPOCHS, criterion=CRITERION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# Load trained model directly from file \n",
    "unet = torch.load('./Model_2', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is NOT available\n",
      "[Patch 0/72200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-38d5106b30cc>\", line 1, in <module>\n",
      "    predict(unet, test_dataloader)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\Desktop\\Cours\\Machine_Learning\\projet_road_2\\Road-Segmentation\\predict.py\", line 51, in predict\n",
      "    for ind_batch, sample_batched in enumerate(dataloader):\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 346, in __next__\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"C:\\Users\\KaabachiBayrem\\Desktop\\Cours\\Machine_Learning\\projet_road_2\\Road-Segmentation\\datasets.py\", line 202, in __getitem__\n",
      "    image = self._extract_image(image_index)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\Desktop\\Cours\\Machine_Learning\\projet_road_2\\Road-Segmentation\\datasets.py\", line 234, in _extract_image\n",
      "    return transformation(image)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 70, in __call__\n",
      "    img = t(img)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\torchvision\\transforms\\transforms.py\", line 136, in __call__\n",
      "    return F.to_pil_image(pic, self.mode)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\torchvision\\transforms\\functional.py\", line 188, in to_pil_image\n",
      "    return Image.fromarray(npimg, mode=mode)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\PIL\\Image.py\", line 2666, in fromarray\n",
      "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 185, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"C:\\Users\\KaabachiBayrem\\.conda\\envs\\ada\\lib\\tokenize.py\", line 447, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "predict(unet, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission for AICrowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i mask_to_submission.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
