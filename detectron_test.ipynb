{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "import random\n",
    "import cv2\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = Path(\"./Datasets/training\")\n",
    "IMAGES = DATASET / \"images\"\n",
    "GROUNDTRUTH = DATASET / \"groundtruth\"\n",
    "IMG_FORMAT = \".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_size(img_path):\n",
    "    \"\"\"\n",
    "    returns height and width of img_path\n",
    "    \"\"\"\n",
    "    image = Image.open(img_path)\n",
    "    width, height = image.size\n",
    "    return width, height\n",
    "\n",
    "def groundtruth_to_sem_seg(img_path):\n",
    "    \"\"\"\n",
    "    Transform a binary .jpg image to torch.tensor for sem_seg\n",
    "    \"\"\"\n",
    "    image = Image.open(img_path)\n",
    "    tensor_mask = transforms.ToTensor()(image).int().squeeze_()\n",
    "    return tensor_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dicts(img_dir):\n",
    "    \"\"\"\n",
    "    Function to return the json dicts to detectron2\n",
    "    \"\"\"\n",
    "    data_dicts = []\n",
    "    for img_path in IMAGES.glob(\"**/*\"+IMG_FORMAT):\n",
    "        filename = img_path\n",
    "        sem_seg_file_name = GROUNDTRUTH / img_path.name\n",
    "        width, height = get_img_size(img_path)\n",
    "        img_id = img_path.name.split(\"_\")[1].split(\".\")[0]\n",
    "        sem_seg = groundtruth_to_sem_seg(sem_seg_file_name)\n",
    "        img_dict = {\n",
    "            \"filename\": str(filename),\n",
    "            \"sem_seg_file_name\": str(sem_seg_file_name),\n",
    "            \"sem_seg\": sem_seg,\n",
    "            \"height\": height,\n",
    "            \"width\": width,\n",
    "            \"img_id\": img_id,\n",
    "        }\n",
    "        data_dicts.append(img_dict)\n",
    "    return data_dicts      \n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_dir = Path(\"./Datasets/training/\")\n",
    "dataset_dicts = get_data_dicts(training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register(\"road_training\", get_data_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"road_training\").set(thing_classes=[\"road\"],\n",
    "                                        stuff_classes=[\"roads\"])\n",
    "road_metadata = MetadataCatalog.get(\"road_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'Datasets/training/images/satImage_083.png', 'sem_seg_file_name': 'Datasets/training/groundtruth/satImage_083.png', 'sem_seg': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32), 'height': 400, 'width': 400, 'img_id': '083'}\n"
     ]
    }
   ],
   "source": [
    "for d in random.sample(dataset_dicts, 3):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"filename\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=road_metadata, \n",
    "                            scale=0.5)\n",
    "    #vis = visualizer.draw_dataset_dict(d)\n",
    "    vis = visualizer.draw_sem_seg(sem_seg=d[\"sem_seg\"])\n",
    "    cv2.imshow(d[\"img_id\"] ,vis.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roads'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_metadata.stuff_classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = Path(\"./Datasets/training/groundtruth/satImage_001.png\")\n",
    "img = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 400])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "transforms.ToTensor()(img).squeeze_().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
